# ENEL645 Final Project - live American Sign Language detection system

1. The main notebook is [asl-model.ipynb](./asl-model.ipynb).
1. The fully trained model is [asl-model.h5](./asl-model.h5).
1. The instructions to run it on TALC is [asl-model.slurm](./asl-model.slurm).
1. The script that opens the camera and detects signs is [live-asl-detection.py](./live-asl-detection.py)

   This is how our detection system looks like:

   ![](./imgs/prediction-c.png)
